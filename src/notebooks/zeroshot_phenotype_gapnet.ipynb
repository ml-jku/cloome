{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a95765a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path, PurePath\n",
    "from collections import OrderedDict\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "\n",
    "from training.datasets import CellPainting\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import DataStructs\n",
    "\n",
    "from hticnn.models import GAPNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b7373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/publicdata/cellpainting/npzs/chembl24/\"\n",
    "val = \"cellpainting-test-phenotype-imgpermol.csv\"\n",
    "classes = \"cellpainting-split-test-imgpermol.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4c0e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"gapnet.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "023f31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(model_path)\n",
    "state_dict = checkpoint[\"state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cba9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = torch.nn.DataParallel(GAPNet(fc_units=1024, dropout=0, num_classes=209, input_shape=[5, 520, 696]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77a9d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): GAPNet(\n",
       "    (block1): Sequential(\n",
       "      (0): Conv2d(5, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): SELU(inplace=True)\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): SELU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): SELU(inplace=True)\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): SELU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (block3): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): SELU(inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): SELU(inplace=True)\n",
       "      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): SELU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (block4): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (1): SELU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (3): SELU(inplace=True)\n",
       "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "      (5): SELU(inplace=True)\n",
       "    )\n",
       "    (gap1): AvgPool2d(kernel_size=(130, 174), stride=(130, 174), padding=0)\n",
       "    (gap2): AvgPool2d(kernel_size=(33, 44), stride=(33, 44), padding=0)\n",
       "    (gap3): AvgPool2d(kernel_size=(16, 22), stride=(16, 22), padding=0)\n",
       "    (gap4): AvgPool2d(kernel_size=(16, 22), stride=(16, 22), padding=0)\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=480, out_features=1024, bias=True)\n",
       "      (1): SELU(inplace=True)\n",
       "      (2): AlphaDropout(p=0, inplace=False)\n",
       "      (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (4): SELU(inplace=True)\n",
       "      (5): AlphaDropout(p=0, inplace=False)\n",
       "      (6): Linear(in_features=1024, out_features=209, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc4f589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.module.classifier = torch.nn.Sequential(*list(model.module.classifier.children())[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01765550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): GAPNet(\n",
       "    (block1): Sequential(\n",
       "      (0): Conv2d(5, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): SELU(inplace=True)\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): SELU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): SELU(inplace=True)\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): SELU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (block3): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): SELU(inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): SELU(inplace=True)\n",
       "      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): SELU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (block4): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (1): SELU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "      (3): SELU(inplace=True)\n",
       "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "      (5): SELU(inplace=True)\n",
       "    )\n",
       "    (gap1): AvgPool2d(kernel_size=(130, 174), stride=(130, 174), padding=0)\n",
       "    (gap2): AvgPool2d(kernel_size=(33, 44), stride=(33, 44), padding=0)\n",
       "    (gap3): AvgPool2d(kernel_size=(16, 22), stride=(16, 22), padding=0)\n",
       "    (gap4): AvgPool2d(kernel_size=(16, 22), stride=(16, 22), padding=0)\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=480, out_features=1024, bias=True)\n",
       "      (1): SELU(inplace=True)\n",
       "      (2): AlphaDropout(p=0, inplace=False)\n",
       "      (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4ed2967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(input_tensor, model, device):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.from_numpy(input_tensor).to(device)\n",
    "        output = model(input_tensor)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4d8d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(dataset, model, device):\n",
    "    all_image_features = []\n",
    "    all_ids = []\n",
    "\n",
    "    print(f\"get_features {device}\")\n",
    "    print(len(dataset))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(DataLoader(dataset, num_workers=20, batch_size=32)):\n",
    "            #print(mols)\n",
    "            imgs = batch\n",
    "            \n",
    "            images = imgs[\"input\"]\n",
    "            ids = imgs[\"ID\"]\n",
    "\n",
    "            img_features = model(images.to(device))\n",
    "            img_features = img_features / img_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            all_image_features.append(img_features)\n",
    "            all_ids.append(ids)\n",
    "\n",
    "        all_ids = list(chain.from_iterable(all_ids))\n",
    "    return torch.cat(all_image_features), all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "177ec67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(df, model, img_path, image_resolution):\n",
    "    # Load the model\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    preprocess_val = ToTensor()\n",
    "\n",
    "    # Load the dataset\n",
    "    val = CellPainting(df,\n",
    "                       img_path,\n",
    "                       transforms = preprocess_val)\n",
    "\n",
    "    # Calculate the image features\n",
    "    print(\"getting_features\")\n",
    "    val_img_features, val_ids = get_features(val, model, device)\n",
    "    \n",
    "    return val_img_features, val_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33d83e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44102\n",
      "getting_features\n",
      "get_features cuda\n",
      "44102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1379/1379 [02:51<00:00,  8.03it/s]\n"
     ]
    }
   ],
   "source": [
    "val_gapnet_features, ids = main(val, model, img_path, 520)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e19a9c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([44102, 1024])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_gapnet_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9961d257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2115\n",
      "getting_features\n",
      "get_features cuda\n",
      "2115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 67/67 [00:17<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "class_img_features, class_ids = main(classes, model, img_path, 520)\n",
    "val_gapnet_features = val_gapnet_features.cpu()\n",
    "class_img_features = class_img_features.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "218c3b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_df = pd.read_csv(classes)\n",
    "classes_df.set_index(\"SAMPLE_KEY\", inplace=True)\n",
    "class_inchis = classes_df.loc[class_ids][\"INCHIKEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16df0d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(val)\n",
    "val_df.set_index(\"SAMPLE_KEY\", inplace=True)\n",
    "val_inchis = val_df.loc[ids][\"INCHIKEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ecb885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {}\n",
    "\n",
    "for i, inchi in enumerate(class_inchis): \n",
    "    class_dict[inchi] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13afc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = np.zeros(len(val_inchis), dtype=int)\n",
    "\n",
    "for i, inchi in enumerate(val_inchis): \n",
    "    label = class_dict[inchi]\n",
    "    ground_truth[i] = int(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf655d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = val_gapnet_features @ class_img_features.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa5688c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R@1': 0.36279533807990566, 'R@5': 1.0747811890617207, 'R@10': 1.7958369234955331}\n"
     ]
    }
   ],
   "source": [
    "ranking = torch.argsort(logits, descending=True)\n",
    "t = torch.tensor(ground_truth, dtype=torch.int16).view(-1,1)\n",
    "\n",
    "preds = torch.where(ranking == t)[1]\n",
    "preds = preds.detach().cpu().numpy()\n",
    "\n",
    "metrics = {}\n",
    "for k in [1, 5, 10]:\n",
    "    metrics[f\"R@{k}\"] = np.mean(preds < k) * 100\n",
    "    \n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e78a3a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R@1': 0.36279533807990566, 'R@5': 1.0747811890617207, 'R@10': 1.7958369234955331}\n",
      "{'R@1': ConfidenceInterval(low=0.0030883812227122357, high=0.0042344008536001725), 'R@5': ConfidenceInterval(low=0.009806440210406235, high=0.011754395603765509), 'R@10': ConfidenceInterval(low=0.016739425902711765, high=0.01924134506550992)}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binomtest\n",
    "\n",
    "n_samples = val_gapnet_features.shape[0]\n",
    "\n",
    "mdict, cis = {}, {}\n",
    "\n",
    "for metric, value in metrics.items():\n",
    "    successes = int(value * n_samples / 100)\n",
    "    btest = binomtest(k=successes, n=n_samples)\n",
    "    mdict[metric] = btest.proportion_estimate * 100\n",
    "    cis[metric] = btest.proportion_ci(confidence_level=0.95)\n",
    "    \n",
    "print(mdict)\n",
    "print(cis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
